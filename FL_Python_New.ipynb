{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://usaupload.com/72Eb/mnist.zip?download_token=122af6eb9e746e2774d3422cba7775dd9ca2a43aaa3156f4c0b5043723a24823\"\n",
    "# name = url.split(\"/\")[-1]\n",
    "# fileName = name.split(\"?\")[0]\n",
    "\n",
    "# !wget $url\n",
    "# !mv $name $fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !unzip mnist.zip;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import models, layers\n",
    "\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Activation\n",
    "# from keras.layers import Dense\n",
    "# from keras import optimizers\n",
    "# from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeed = 42\n",
    "np.random.seed(mySeed)\n",
    "random.seed(mySeed)\n",
    "tf.random.set_seed(mySeed)\n",
    "# torch.manual_seed(mySeed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_bypath(lst_image_paths, verbose=-1):\n",
    "    \"\"\" Expect to read images where each class is in a separate directory,\n",
    "        For example: images of type 0 are in folder 0\n",
    "    \"\"\"\n",
    "\n",
    "    lstData = list()\n",
    "    lstLabel = list()\n",
    "\n",
    "    for (i, imgPath) in enumerate(lst_image_paths):\n",
    "        img = cv2.imread(imgPath, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.flatten()\n",
    "        img = img/255\n",
    "        \n",
    "        label = imgPath.split(os.path.sep)[-2]\n",
    "        \n",
    "        lstData.append(img)\n",
    "        lstLabel.append(label)\n",
    "        \n",
    "        # show an update every `verbose` images\n",
    "        if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
    "            print(f\"[INFO] processed {i+1}/{len(lst_image_paths)}\")\n",
    "            break\n",
    "\n",
    "    return lstData, lstLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10000/42000\n",
      "Train x=(8000, 784), y=(8000, 3)\n",
      "Test x=(2000, 784), y=(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "img_path = \"mnist/trainingSet/trainingSet\"\n",
    "# img_path = \"/content/mnist/trainingSet/trainingSet\"\n",
    "\n",
    "# Generate a list of all images\n",
    "lst_image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "lstData, lstLabel = load_mnist_bypath(lst_image_paths, verbose=10000)\n",
    "data = np.array(lstData)\n",
    "labels = np.array(lstLabel)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "oneHotEncoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "y_train = oneHotEncoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = oneHotEncoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(f\"Train x={x_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test x={x_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients_with_data_assignment(image_list, label_list, num_clients=10, initial=\"client\"):\n",
    "    \"\"\" return: A dictionary with the customer id as the dictionary key and the value\n",
    "                will be the data fragment - tuple of images and labels.\n",
    "        args:\n",
    "            image_list: a numpy array object with the images\n",
    "            label_list: list of binarized labels (one-hot encoded)\n",
    "            num_clients: number of customers (clients)\n",
    "            initial: the prefix of the clients, e.g., client_1\n",
    "     \"\"\"\n",
    "\n",
    "    # create list of client names\n",
    "    client_names = [f\"{initial}_{i+1}\" for i in range(num_clients)]\n",
    "\n",
    "    # shuffle the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # shard the data and split it for each customer\n",
    "    size = len(data) // num_clients\n",
    "    shards = [data[i: i+size]  for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    # Check if the fragment number is equal to the number of clients\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i]: shards[i]  for i in range(len(client_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data_shard, batch_size=32):\n",
    "    \"\"\" Receives a piece of data (imgs, labels) from a client and creates a tensorflow Dataset object in it\n",
    "        args:\n",
    "            data_shard: data and labels that make up a customer's data shard\n",
    "            batch_size: batch size\n",
    "        return:\n",
    "            data tensorflow Dataset object\n",
    "    \"\"\"\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_model_weights(weight, scalar):\n",
    "    \"\"\" Scale the model weights \"\"\"\n",
    "    \n",
    "    weight_final = []\n",
    "    for i in range(len(weight)):\n",
    "        weight_final.append(weight[i] * scalar)\n",
    "\n",
    "    return weight_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(100, activation=\"relu\", input_shape=shape),\n",
    "            layers.Dense(100, activation=\"relu\"),\n",
    "            layers.Dense(classes, activation=\"softmax\"),\n",
    "            ])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_clients = 2\n",
    "batch_size = 32\n",
    "\n",
    "client_select_rate = 1\n",
    "\n",
    "comms_round = 1\n",
    "client_epochs = 1\n",
    "lr = 0.01\n",
    "# optimizer = optimizers.Adam(learning_rate=lr, decay=lr/comms_round)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr, decay=lr/comms_round)\n",
    "# optimizer = \"adam\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clients and batched data\n",
    "\n",
    "clients = create_clients_with_data_assignment(x_train, y_train, num_clients=num_clients, initial=\"client\")\n",
    "\n",
    "# Bached data with tensorflow data object\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data, batch_size)\n",
    "\n",
    "# Convert labels to tensorflow data object\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[array([[-0.10273435, -0.04704752,  0.00808045, ...,  0.00588167,\n",
      "        -0.00892175,  0.04568824],\n",
      "       [-0.08046278, -0.08837207,  0.07953827, ..., -0.01924175,\n",
      "        -0.0003405 ,  0.05012556],\n",
      "       [-0.1063384 ,  0.07703272,  0.1499303 , ..., -0.06314262,\n",
      "         0.07507354, -0.0030708 ],\n",
      "       ...,\n",
      "       [ 0.03414189,  0.04948349, -0.01683494, ..., -0.01540671,\n",
      "        -0.00967073, -0.07834828],\n",
      "       [ 0.01090276,  0.02770779, -0.04498865, ...,  0.01563124,\n",
      "        -0.06267883,  0.01385543],\n",
      "       [-0.00375625,  0.04419962, -0.04669923, ..., -0.076101  ,\n",
      "         0.07397996,  0.02152166]], dtype=float32), array([ 0.03723201, -0.04715949, -0.026675  , -0.04260453,  0.03148137,\n",
      "        0.04119245, -0.04683571, -0.01977016, -0.07218079, -0.01400003,\n",
      "       -0.10265958,  0.01042398, -0.06595653, -0.01400225, -0.04816522,\n",
      "       -0.05215771, -0.01774357, -0.03047089, -0.01886009,  0.00966556,\n",
      "       -0.0549637 ,  0.03881105, -0.07077589, -0.00620759,  0.00185925,\n",
      "        0.01631067,  0.04037813,  0.00283107, -0.05578178, -0.04754794,\n",
      "       -0.01379987,  0.0156823 , -0.04822459, -0.07094528, -0.00395515,\n",
      "       -0.05998914,  0.02758307,  0.01290182, -0.01599791,  0.03929393,\n",
      "       -0.06392642, -0.05643583,  0.01140266, -0.01093272, -0.01912649,\n",
      "       -0.08257724, -0.04822549, -0.07100864, -0.04783775,  0.03144199,\n",
      "       -0.08266333, -0.08337688, -0.02622186,  0.02436901, -0.0636531 ,\n",
      "       -0.032479  , -0.04822823,  0.03792408, -0.04822777,  0.00202535,\n",
      "       -0.01835936, -0.00446334,  0.02968733, -0.05489881, -0.04512729,\n",
      "       -0.05494712,  0.03393055, -0.03496021, -0.08228634,  0.02757202,\n",
      "        0.0114338 , -0.00265599,  0.05423367, -0.04124694, -0.06945139,\n",
      "       -0.04659661, -0.04953082, -0.01495561, -0.03992843, -0.06088679,\n",
      "       -0.07314097, -0.03071982,  0.00474601, -0.06472232, -0.04139283,\n",
      "       -0.04820639, -0.02230976, -0.07018936,  0.01124176, -0.0240875 ,\n",
      "        0.001009  ,  0.03280959,  0.02126902,  0.02965945, -0.04821717,\n",
      "       -0.03909143, -0.06428382, -0.03429885, -0.0623582 ,  0.05138769],\n",
      "      dtype=float32), array([[-0.04105549, -0.04641354, -0.09233667, ..., -0.12860964,\n",
      "         0.0769325 , -0.21654536],\n",
      "       [ 0.09752505,  0.07693777, -0.0663199 , ..., -0.09056797,\n",
      "        -0.08531123, -0.1288447 ],\n",
      "       [ 0.04642583, -0.01325515,  0.09315161, ..., -0.11627191,\n",
      "         0.03628016, -0.03874115],\n",
      "       ...,\n",
      "       [ 0.15330702, -0.04846604,  0.03316032, ...,  0.11638056,\n",
      "        -0.023699  , -0.00472913],\n",
      "       [-0.16395913,  0.0417553 ,  0.12576196, ...,  0.06473473,\n",
      "        -0.01798511, -0.0091185 ],\n",
      "       [-0.06392879, -0.07388619, -0.03363683, ..., -0.20511997,\n",
      "        -0.147707  , -0.11775355]], dtype=float32), array([-0.02745954,  0.00797684, -0.03612019, -0.04798898, -0.01441651,\n",
      "        0.04808927, -0.02603551, -0.04175762,  0.00690149, -0.04720785,\n",
      "       -0.02224632,  0.00989643, -0.0553166 , -0.06281897, -0.08917063,\n",
      "       -0.0688363 , -0.03429288, -0.00498496, -0.05973136,  0.10087446,\n",
      "        0.05270107, -0.02949353,  0.06065743,  0.03915047, -0.04808409,\n",
      "        0.01079034, -0.03674338,  0.00646304, -0.05156652, -0.0289109 ,\n",
      "       -0.05886183, -0.05093786,  0.01492774,  0.05524283,  0.03424671,\n",
      "       -0.0203598 , -0.05043198, -0.00806302, -0.05361318,  0.07121056,\n",
      "       -0.02627692, -0.0573156 , -0.07297607,  0.0545349 , -0.05063091,\n",
      "        0.07437476, -0.04822613,  0.00191858,  0.05394355,  0.05035331,\n",
      "       -0.06273794,  0.00498284,  0.05114723,  0.0137054 ,  0.00918656,\n",
      "       -0.02446218,  0.05701901,  0.10878051, -0.04847343,  0.02025102,\n",
      "       -0.04823298, -0.07431946, -0.02675448, -0.00648843, -0.10038029,\n",
      "       -0.07154668,  0.03871181, -0.02951088, -0.08648205,  0.02575024,\n",
      "       -0.05894666,  0.06364097,  0.03728325, -0.04720384, -0.00238884,\n",
      "       -0.03940533,  0.02098706, -0.0730191 , -0.0591263 , -0.0749677 ,\n",
      "       -0.08674981, -0.06232459, -0.12272283,  0.00769641, -0.01569751,\n",
      "        0.03989137, -0.02017131, -0.07809544,  0.05559085,  0.06208977,\n",
      "       -0.04070991, -0.07704098, -0.01994668,  0.06040085,  0.06224047,\n",
      "        0.00196615, -0.05606189, -0.06102243,  0.01091738, -0.08660496],\n",
      "      dtype=float32), array([[-0.21064965, -0.14320873,  0.1842021 ],\n",
      "       [-0.18569972, -0.36357066, -0.09624673],\n",
      "       [ 0.10411574, -0.22577783, -0.1712307 ],\n",
      "       [-0.02398697, -0.2535657 , -0.16390151],\n",
      "       [-0.09745521, -0.04226751, -0.12589611],\n",
      "       [-0.05456873,  0.2723514 , -0.07206239],\n",
      "       [-0.12231463, -0.14015336, -0.00451352],\n",
      "       [ 0.07889371, -0.03196087, -0.11245147],\n",
      "       [ 0.22769183,  0.24492387,  0.02212709],\n",
      "       [-0.0123046 ,  0.23681659, -0.19285291],\n",
      "       [-0.03412602, -0.16661577,  0.05582979],\n",
      "       [-0.05165984,  0.07791422, -0.14953326],\n",
      "       [-0.01045193, -0.00097119,  0.00096998],\n",
      "       [-0.10151836, -0.08208936,  0.10129899],\n",
      "       [ 0.04122004, -0.02240293,  0.03144671],\n",
      "       [-0.1607709 ,  0.03966116, -0.03266542],\n",
      "       [ 0.08367418, -0.10070585,  0.0238186 ],\n",
      "       [ 0.12135731, -0.22271031,  0.20051315],\n",
      "       [ 0.18063892,  0.06731181, -0.09270966],\n",
      "       [-0.03794079,  0.12411559,  0.11292686],\n",
      "       [-0.18251799,  0.18489616, -0.00798924],\n",
      "       [ 0.17327905, -0.13728619,  0.18510461],\n",
      "       [-0.22687657,  0.07936681,  0.0228559 ],\n",
      "       [-0.07735524,  0.049947  , -0.21175447],\n",
      "       [ 0.01714201, -0.03932487,  0.14420702],\n",
      "       [ 0.02135046,  0.09710713, -0.06173955],\n",
      "       [ 0.03996811, -0.22536077, -0.03899651],\n",
      "       [-0.1854158 ,  0.04193797, -0.08296527],\n",
      "       [ 0.2005437 , -0.08952285,  0.09966293],\n",
      "       [-0.3030331 , -0.0835272 , -0.11988238],\n",
      "       [-0.16078678, -0.15259393, -0.13392113],\n",
      "       [ 0.00609214, -0.17059185, -0.14918539],\n",
      "       [-0.22354321, -0.00900122,  0.19623625],\n",
      "       [-0.24434976,  0.23500599, -0.24106495],\n",
      "       [-0.15061425, -0.02960695, -0.16474912],\n",
      "       [ 0.12108704,  0.21700655, -0.07194147],\n",
      "       [-0.11782543, -0.11731791,  0.06232539],\n",
      "       [-0.25680232, -0.14475538, -0.20426892],\n",
      "       [ 0.10614893, -0.10086977, -0.22048311],\n",
      "       [-0.1467112 ,  0.11824607,  0.07434941],\n",
      "       [-0.04825313, -0.2556225 ,  0.04100221],\n",
      "       [ 0.07649489, -0.23779655,  0.1723017 ],\n",
      "       [-0.10409464, -0.1277276 , -0.22433585],\n",
      "       [-0.00963835,  0.14655054,  0.19743209],\n",
      "       [ 0.11963055, -0.2129602 , -0.13639235],\n",
      "       [-0.27057564,  0.06323371, -0.0835081 ],\n",
      "       [-0.16243033, -0.14230625, -0.13804999],\n",
      "       [-0.16783166,  0.1446007 , -0.00413035],\n",
      "       [-0.24164923,  0.00454472, -0.15251803],\n",
      "       [-0.14449751,  0.21163133, -0.12725373],\n",
      "       [ 0.10430658,  0.01616042, -0.19159701],\n",
      "       [ 0.14222804,  0.2088005 , -0.16245367],\n",
      "       [-0.02689494,  0.25503042,  0.13969779],\n",
      "       [-0.2685034 , -0.11095501, -0.12784684],\n",
      "       [ 0.06397702,  0.07146236,  0.07866123],\n",
      "       [-0.05911614,  0.0803781 ,  0.21190804],\n",
      "       [-0.245598  ,  0.13898301, -0.18447363],\n",
      "       [-0.20466891,  0.06908077, -0.00516357],\n",
      "       [-0.08620343, -0.24476488,  0.15553078],\n",
      "       [-0.2299108 , -0.13495661, -0.14996658],\n",
      "       [-0.05058343,  0.18396825,  0.1468511 ],\n",
      "       [-0.09979   , -0.23450264,  0.14526467],\n",
      "       [ 0.0972764 ,  0.10994554, -0.31288758],\n",
      "       [ 0.00138206, -0.26271287, -0.20591587],\n",
      "       [ 0.11886093,  0.03490223, -0.02087545],\n",
      "       [-0.01178201,  0.05247529,  0.09652469],\n",
      "       [ 0.05037476, -0.10567613,  0.15741485],\n",
      "       [-0.02860394,  0.06757369, -0.10311002],\n",
      "       [ 0.11026616, -0.01069086,  0.10702574],\n",
      "       [-0.17254898,  0.17913069,  0.04165385],\n",
      "       [ 0.01745063,  0.00104566, -0.20437615],\n",
      "       [ 0.0235232 ,  0.2517362 , -0.1186923 ],\n",
      "       [-0.06561157,  0.12825598,  0.01344583],\n",
      "       [-0.2390108 , -0.13583443, -0.1396431 ],\n",
      "       [-0.01882305, -0.19749966,  0.00272306],\n",
      "       [ 0.09535997, -0.0512551 , -0.23216179],\n",
      "       [-0.05598069, -0.15723106,  0.07335953],\n",
      "       [ 0.02993613, -0.06500429, -0.05865271],\n",
      "       [-0.1208469 , -0.18835224, -0.04519325],\n",
      "       [-0.08632061, -0.09102611, -0.0851009 ],\n",
      "       [ 0.00486841, -0.09766944, -0.03465497],\n",
      "       [-0.07414868,  0.01842814, -0.01048266],\n",
      "       [ 0.10262819, -0.00387057, -0.00380028],\n",
      "       [-0.18914524, -0.02741685, -0.02537106],\n",
      "       [ 0.01316037, -0.14058042,  0.19551405],\n",
      "       [-0.00804404,  0.15988827, -0.16921045],\n",
      "       [ 0.14341187,  0.24227352, -0.00979282],\n",
      "       [ 0.09157623, -0.21842515, -0.02042668],\n",
      "       [ 0.03488242, -0.1019538 ,  0.19604151],\n",
      "       [-0.15278162, -0.05243638, -0.18299164],\n",
      "       [ 0.20090011, -0.25180975, -0.21702439],\n",
      "       [ 0.07189418, -0.07433221, -0.00186781],\n",
      "       [ 0.14401723,  0.1640466 , -0.05916514],\n",
      "       [-0.25130364,  0.14622228, -0.0142874 ],\n",
      "       [-0.26313713,  0.1103764 ,  0.24253307],\n",
      "       [ 0.18866952,  0.13107152, -0.07533313],\n",
      "       [-0.08966541, -0.10280708, -0.08875729],\n",
      "       [-0.30187628, -0.1000718 ,  0.16256766],\n",
      "       [ 0.0028405 , -0.04759025, -0.22570287],\n",
      "       [ 0.05833303, -0.00462038,  0.11794478]], dtype=float32), array([-0.06675664,  0.06099342,  0.00333586], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "mlp_global = MLP()\n",
    "global_model = mlp_global.build(x_train.shape[1:], y_train.shape[-1])\n",
    "\n",
    "# Global training loop collection\n",
    "for comm_round in range(comms_round):\n",
    "\n",
    "    # global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "\n",
    "    # initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    # randomize client - using keys\n",
    "    client_names = list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    client_select = client_names[0: int(num_clients*client_select_rate)]\n",
    "\n",
    "    # calculate total training data across selected clients\n",
    "    # if all clients have a same length\n",
    "    global_count = len(clients[client_select[0]]) * len(client_select)\n",
    "\n",
    "    # loop through each client and create a new local model\n",
    "    for client in client_select:\n",
    "        mlp_local = MLP()\n",
    "        local_model = mlp_local.build(x_train.shape[1:], y_train.shape[-1])\n",
    "        local_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        # set the weight of the local model from the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "\n",
    "        # fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=client_epochs, verbose=0)\n",
    "\n",
    "        # scale the model weights and added to the list\n",
    "        local_count = len(clients[client])\n",
    "        scaling_factor = local_count / global_count\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "        print(\"test\")\n",
    "        print(local_model.get_weights())\n",
    "        \n",
    "        break\n",
    "\n",
    "#         # Check local accuracy\n",
    "#         # acc_l, loss_l = check_local_loss(client, local_model)\n",
    "\n",
    "#         # clear session to free memory after each communication round\n",
    "#         K.clear_session()\n",
    "\n",
    "#     # to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "#     average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "#     # update global model\n",
    "#     global_model.set_weights(average_weights)\n",
    "\n",
    "#     # test global model and print out metrics after each communications round\n",
    "#     for (X_test, Y_test) in test_batched:\n",
    "#         global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
