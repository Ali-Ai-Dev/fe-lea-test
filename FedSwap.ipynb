{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import models, layers\n",
    "from keras import backend\n",
    "\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeed = 42\n",
    "# np.random.seed(mySeed)\n",
    "random.seed(mySeed)\n",
    "tf.random.set_seed(mySeed)\n",
    "# torch.manual_seed(mySeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_clients = 4\n",
    "batch_size = 32\n",
    "total_steps = 2\n",
    "\n",
    "lr = 0.01\n",
    "# optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr, decay=lr/total_steps)\n",
    "optimizer = \"adam\"\n",
    "loss_cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics = [\"accuracy\"]\n",
    "client_epochs = 1\n",
    "\n",
    "swap_step = 2\n",
    "n_swap_between_avg = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x=(60000, 28, 28), y=(60000, 10)\n",
      "Test x=(10000, 28, 28), y=(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "# OneHotEncoded Labels\n",
    "oneHotEncoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "y_train = oneHotEncoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = oneHotEncoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(f\"Train x={x_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test x={x_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x=(60000, 784), y=(60000, 10)\n",
      "Test x=(10000, 784), y=(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Remove one dimension for data\n",
    "x_train = x_train.reshape(-1, x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(-1, x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "print(f\"Train x={x_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test x={x_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients_with_data_assignment(values_list, label_list, num_clients=10, initial=\"client\"):\n",
    "    \"\"\" return: A dictionary with the customer id as the dictionary key and the value\n",
    "                will be the data fragment - tuple of values and labels.\n",
    "        args:\n",
    "            values_list: a numpy array object with the values\n",
    "            label_list: list of binarized labels (one-hot encoded)\n",
    "            num_clients: number of customers (clients)\n",
    "            initial: the prefix of the clients, e.g., client_1\n",
    "     \"\"\"\n",
    "\n",
    "    # create list of client names\n",
    "    client_names = [f\"{initial}_{i+1}\" for i in range(num_clients)]\n",
    "\n",
    "    # shuffle the data\n",
    "    data = list(zip(values_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # shard the data and split it for each customer\n",
    "    size = len(data) // num_clients\n",
    "    shards = [data[i: i+size]  for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    # Check if the fragment number is equal to the number of clients\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i]: shards[i]  for i in range(len(client_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data_shard, batch_size=32):\n",
    "    \"\"\" Receives a piece of data (values, labels) from a client and creates a tensorflow Dataset object in it\n",
    "        args:\n",
    "            data_shard: values and labels that make up a customer's data shard\n",
    "            batch_size: batch size\n",
    "        return:\n",
    "            data tensorflow Dataset object\n",
    "    \"\"\"\n",
    "    #seperate shard into data and labels lists\n",
    "    values, labels = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(values), list(labels)))\n",
    "    return dataset.shuffle(len(labels), reshuffle_each_iteration=False).batch(batch_size)\n",
    "\n",
    "\n",
    "### Explaining the function with example ###\n",
    "# test = list(zip([[1, 2], [3, 4], [5, 6], [7, 8]], [\"a\", \"b\", \"c\", \"d\"]))\n",
    "# print(test)\n",
    "# data, label = zip(*test)\n",
    "# print(data)\n",
    "# print(label)\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "# test1 = dataset.shuffle(len(label))\n",
    "# print(list(test1.as_numpy_iterator()))\n",
    "# test2 = dataset.shuffle(len(label)).batch(3)\n",
    "# print(list(test2.as_numpy_iterator()))\n",
    "# list(test2)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clients and batched data\n",
    "\n",
    "clients = create_clients_with_data_assignment(x_train, y_train, num_clients=num_clients, initial=\"client\")\n",
    "\n",
    "# Bached data with tensorflow data object\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data, batch_size)\n",
    "\n",
    "test_batch_size = len(y_test)\n",
    "# Convert test data to tensorflow data object\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(test_batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(100, activation=\"relu\", input_shape=shape),\n",
    "            layers.Dense(100, activation=\"relu\"),\n",
    "            layers.Dense(classes, activation=\"softmax\"),\n",
    "            ])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all clients with same weight\n",
    "mlp_global = MLP()\n",
    "global_model = mlp_global.build(x_train.shape[1:], y_train.shape[-1])\n",
    "global_weights = global_model.get_weights()\n",
    "client_weights = dict.fromkeys(list(clients_batched.keys()), global_weights)\n",
    "\n",
    "client_select = list(clients_batched.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_swap(client):\n",
    "    random_num = random.randint(0, len(client_select)-1)\n",
    "    random_client = client_select[random_num]\n",
    "\n",
    "    temp_weight = client_weights[random_client]\n",
    "    client_weights[random_client] = client_weights[client]\n",
    "\n",
    "    return temp_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in total_steps:\n",
    "    for client in client_select:\n",
    "        mlp_local = MLP()\n",
    "        local_model = mlp_local.build(x_train.shape[1:], y_train.shape[-1])\n",
    "        local_model.compile(optimizer=optimizer, loss=loss_cce, metrics=metrics)\n",
    "\n",
    "        local_model.set_weights(client_weights[client])\n",
    "        local_model.fit(clients_batched[client], epochs=client_epochs, verbose=0)\n",
    "\n",
    "        backend.clear_session()\n",
    "    \n",
    "    if (step % swap_step == 0) and (step % (swap_step*n_swap_between_avg) != 0):\n",
    "        for client in client_select:\n",
    "            client_weights[client] = fed_swap(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
