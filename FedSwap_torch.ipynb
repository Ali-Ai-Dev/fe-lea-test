{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd \"/content/drive/MyDrive/ColabTemp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using '{device}' device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeed = 42\n",
    "torch.manual_seed(mySeed)\n",
    "np.random.seed(mySeed)\n",
    "random.seed(mySeed)\n",
    "# tf.random.set_seed(mySeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_clients = 3\n",
    "batch_size = 1000\n",
    "total_steps = 7\n",
    "client_select_percentage = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "client_epochs = 2\n",
    "\n",
    "swap_step = 2\n",
    "n_swap_bet_avg_p1 = 3 # p1=plus one to your number, if need 2 swap between avg, enter 3\n",
    "\n",
    "remain = 0.1 # Remove some data for running faster in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_selects = None\n",
    "client_weights = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "torch.Size([3, 32, 32])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"../datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10).scatter_(dim=0, index=torch.tensor(y), value=1)),\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"../datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10).scatter_(dim=0, index=torch.tensor(y), value=1)),\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Remove some data for running faster in test\n",
    "print(len(train_data))\n",
    "train_data = torch.utils.data.Subset(train_data, range(0, int(len(train_data)*remain)))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random dataset split\n",
    "client_data_size = np.array([len(train_data)//num_clients]*num_clients)\n",
    "data_remain = len(train_data) % num_clients\n",
    "for i in range(data_remain):\n",
    "    client_data_size[-1-i] += 1\n",
    "\n",
    "client_datasets = torch.utils.data.random_split(train_data, client_data_size)\n",
    "\n",
    "### None random dataset split\n",
    "# client_datasets = list()\n",
    "# i = 0\n",
    "# for j in client_data_size:\n",
    "#     client_datasets.append(torch.utils.data.Subset(train_data, range(i, i+j)))\n",
    "#     i += j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for each client\n",
    "client_dataloaders = np.zeros(num_clients, dtype=object)\n",
    "for i, dataset in enumerate(client_datasets):\n",
    "    client_dataloaders[i] = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "input_flat_size = torch.flatten(train_data[0][0]).shape[0]\n",
    "nClasses = train_data[0][1].shape[0]\n",
    "\n",
    "class NeuralNetworkMnistMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(input_flat_size, 256)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(256, 128)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(128, 64)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('fc4', nn.Linear(64, nClasses)),\n",
    "        ]))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return list(self.parameters())\n",
    "    \n",
    "    def set_weights(self, parameters_list):\n",
    "        for i, param in enumerate(self.parameters()):\n",
    "            param.data = parameters_list[i].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworkMnistMLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "global_model = NeuralNetworkMnistMLP().to(device)\n",
    "print(global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_clients_and_assign_weights(global_weights):\n",
    "    global client_selects\n",
    "    global client_weights\n",
    "\n",
    "    lst = np.arange(0, num_clients)\n",
    "    np.random.shuffle(lst)\n",
    "    client_selects = lst[: int(len(lst)*client_select_percentage)]\n",
    "\n",
    "    client_weights = {i: copy.deepcopy(global_weights)  for i in client_selects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = global_model.get_weights()\n",
    "select_clients_and_assign_weights(global_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_model_weights(weights, scalar):\n",
    "    \"\"\" Scale the model weights \"\"\"\n",
    "\n",
    "    scaled_weights = list()\n",
    "    for i in range(len(weights)):\n",
    "        scaled_weights.append(weights[i] * scalar)\n",
    "\n",
    "    return scaled_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scaled_weights(client_scaled_weights):\n",
    "    \"\"\" Return the sum of the listed scaled weights.\n",
    "        axis_O is equivalent to the average weight of the weights \"\"\"\n",
    "\n",
    "    avg_weights = list()\n",
    "    # get the average gradient accross all client gradients\n",
    "    for gradient_list_tuple in zip(*client_scaled_weights):\n",
    "        gradient_list_tuple = [tensor.tolist()  for tensor in gradient_list_tuple]\n",
    "        layer_mean = torch.sum(torch.tensor(gradient_list_tuple), axis=0).to(device)\n",
    "        avg_weights.append(layer_mean)\n",
    "\n",
    "    return avg_weights\n",
    "\n",
    "\n",
    "### Explaining the function with example ###\n",
    "# t = (torch.tensor([[[2, 3],[3, 4]], [[3, 4],[4, 5]], [[4, 5],[5, 6]]]),\n",
    "#      torch.tensor([[[5, 6],[6, 7]], [[6, 7],[7, 8]], [[7, 8],[8, 9]]]))\n",
    "# t = [i.tolist() for i in t]\n",
    "# for y in zip(*t):\n",
    "#     print(y)\n",
    "#     print(torch.sum(torch.tensor(y), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg():\n",
    "    # calculate total training data across clients\n",
    "    global_count = 0\n",
    "    for client in client_selects:\n",
    "        global_count += len(client_dataloaders[client].dataset)\n",
    "\n",
    "    # initial list to collect clients weight after scalling\n",
    "    client_scaled_weights = list()\n",
    "    for client in client_selects:\n",
    "        local_count = len(client_dataloaders[client].dataset)\n",
    "        scaling_factor = local_count / global_count\n",
    "        scaled_weights = scale_model_weights(client_weights[client], scaling_factor)\n",
    "        client_scaled_weights.append(scaled_weights)\n",
    "\n",
    "    # to get the average over all the clients model, we simply take the sum of the scaled weights\n",
    "    avg_weights = sum_scaled_weights(client_scaled_weights)\n",
    "\n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_swap(client):\n",
    "    random_num = random.randint(0, len(client_selects)-1)\n",
    "    random_client = client_selects[random_num]\n",
    "\n",
    "    temp_weights = client_weights[random_client]\n",
    "    client_weights[random_client] = client_weights[client]\n",
    "\n",
    "    return temp_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neural_network(dataloader, model, loss_fn):\n",
    "    data_size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct_items = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct_items += (pred.argmax(1) == y.argmax(1)).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / num_batches\n",
    "    accuracy = correct_items / data_size\n",
    "    print(f\"Test Error: \\nAccuracy: {(accuracy*100):>0.1f}%, Loss: {avg_loss:>8f}\\n\")\n",
    "\n",
    "    return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(dataloader, model, loss_fn, optimizer):\n",
    "    data_size = len(dataloader.dataset)\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        print_step = np.ceil(len(dataloader)/10)\n",
    "        if batch % print_step == 0:\n",
    "            loss_per_batch = running_loss / print_step\n",
    "            current_item = (batch+1)*len(x)\n",
    "            print(f\"loss: {loss_per_batch:>7f}  [{current_item:>5d}/{data_size:>5d}]\")\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clinet(dataloader, model):\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(client_epochs):\n",
    "        train_neural_network(dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.302497  [ 1000/ 1666]\n",
      "loss: 2.310790  [ 1332/ 1666]\n",
      "loss: 2.324357  [ 1000/ 1666]\n",
      "loss: 2.331970  [ 1332/ 1666]\n",
      "loss: 2.302649  [ 1000/ 1667]\n",
      "loss: 2.338618  [ 1334/ 1667]\n",
      "loss: 2.300561  [ 1000/ 1667]\n",
      "loss: 2.322997  [ 1334/ 1667]\n",
      "loss: 2.302762  [ 1000/ 1667]\n",
      "loss: 2.302717  [ 1334/ 1667]\n",
      "loss: 2.345971  [ 1000/ 1667]\n",
      "loss: 2.358479  [ 1334/ 1667]\n",
      "Test Error: \n",
      "Accuracy: 10.0%, Loss: 2.317127\n",
      "\n",
      "loss: 2.320235  [ 1000/ 1667]\n",
      "loss: 2.308868  [ 1334/ 1667]\n",
      "loss: 2.326998  [ 1000/ 1667]\n",
      "loss: 2.359330  [ 1334/ 1667]\n",
      "loss: 2.310596  [ 1000/ 1667]\n",
      "loss: 2.346739  [ 1334/ 1667]\n",
      "loss: 2.321802  [ 1000/ 1667]\n",
      "loss: 2.367033  [ 1334/ 1667]\n",
      "loss: 2.323923  [ 1000/ 1666]\n",
      "loss: 2.323577  [ 1332/ 1666]\n",
      "loss: 2.326824  [ 1000/ 1666]\n",
      "loss: 2.343424  [ 1332/ 1666]\n",
      "loss: 2.363230  [ 1000/ 1667]\n",
      "loss: 2.350206  [ 1334/ 1667]\n",
      "loss: 2.356150  [ 1000/ 1667]\n",
      "loss: 2.360700  [ 1334/ 1667]\n",
      "loss: 2.366019  [ 1000/ 1667]\n",
      "loss: 2.350806  [ 1334/ 1667]\n",
      "loss: 2.322747  [ 1000/ 1667]\n",
      "loss: 2.314380  [ 1334/ 1667]\n",
      "loss: 2.349495  [ 1000/ 1666]\n",
      "loss: 2.362683  [ 1332/ 1666]\n",
      "loss: 2.314039  [ 1000/ 1666]\n",
      "loss: 2.302606  [ 1332/ 1666]\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "1 0\n",
      "tensor([ 0.0028,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([ 0.0013,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "2 1\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0013,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "0 1\n",
      "tensor([ 0.0013,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "loss: 2.356150  [ 1000/ 1667]\n",
      "loss: 2.360700  [ 1334/ 1667]\n",
      "loss: 2.364150  [ 1000/ 1667]\n",
      "loss: 2.348706  [ 1334/ 1667]\n",
      "loss: 2.301913  [ 1000/ 1667]\n",
      "loss: 2.297717  [ 1334/ 1667]\n",
      "loss: 2.294689  [ 1000/ 1667]\n",
      "loss: 2.280180  [ 1334/ 1667]\n",
      "loss: 2.308013  [ 1000/ 1666]\n",
      "loss: 2.296156  [ 1332/ 1666]\n",
      "loss: 2.288088  [ 1000/ 1666]\n",
      "loss: 2.259916  [ 1332/ 1666]\n",
      "loss: 2.353150  [ 1000/ 1667]\n",
      "loss: 2.365198  [ 1334/ 1667]\n",
      "loss: 2.356150  [ 1000/ 1667]\n",
      "loss: 2.360700  [ 1334/ 1667]\n",
      "loss: 2.263354  [ 1000/ 1667]\n",
      "loss: 2.312451  [ 1334/ 1667]\n",
      "loss: 2.335914  [ 1000/ 1667]\n",
      "loss: 2.316206  [ 1334/ 1667]\n",
      "loss: 2.278171  [ 1000/ 1666]\n",
      "loss: 2.365792  [ 1332/ 1666]\n",
      "loss: 2.320215  [ 1000/ 1666]\n",
      "loss: 2.323823  [ 1332/ 1666]\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "1 0\n",
      "tensor([ 0.0980,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "2 2\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0159, -0.0096,  ...,  0.0062, -0.0232, -0.0282],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "0 1\n",
      "tensor([ 0.0980,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 7.6283e-05,  1.3240e-02, -1.2409e-02,  ...,  5.0456e-03,\n",
      "        -2.4180e-02, -2.9401e-02], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0980,  0.0145, -0.0111,  ...,  0.0069, -0.0224, -0.0279],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "loss: 2.362150  [ 1000/ 1667]\n",
      "loss: 2.351705  [ 1334/ 1667]\n",
      "loss: 2.360150  [ 1000/ 1667]\n",
      "loss: 2.354703  [ 1334/ 1667]\n",
      "loss: 2.318048  [ 1000/ 1667]\n",
      "loss: 2.324003  [ 1334/ 1667]\n",
      "loss: 2.289699  [ 1000/ 1667]\n",
      "loss: 2.286847  [ 1334/ 1667]\n",
      "loss: 2.343995  [ 1000/ 1666]\n",
      "loss: 2.340491  [ 1332/ 1666]\n",
      "loss: 2.298899  [ 1000/ 1666]\n",
      "loss: 2.292223  [ 1332/ 1666]\n",
      "loss: 2.359150  [ 1000/ 1667]\n",
      "loss: 2.356203  [ 1334/ 1667]\n",
      "loss: 2.357150  [ 1000/ 1667]\n",
      "loss: 2.359201  [ 1334/ 1667]\n",
      "loss: 2.292400  [ 1000/ 1667]\n",
      "loss: 2.287169  [ 1334/ 1667]\n",
      "loss: 2.282417  [ 1000/ 1667]\n",
      "loss: 2.271211  [ 1334/ 1667]\n",
      "loss: 2.288151  [ 1000/ 1666]\n",
      "loss: 2.267083  [ 1332/ 1666]\n",
      "loss: 2.251415  [ 1000/ 1666]\n",
      "loss: 2.257365  [ 1332/ 1666]\n",
      "Test Error: \n",
      "Accuracy: 10.0%, Loss: 2.309301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in range(0, total_steps):\n",
    "    for client in client_selects:\n",
    "        local_model = NeuralNetworkMnistMLP().to(device)\n",
    "        local_model.set_weights(client_weights[client])\n",
    "        train_clinet(client_dataloaders[client], local_model)\n",
    "        client_weights[client] = local_model.get_weights()\n",
    "\n",
    "        del local_model\n",
    "    \n",
    "    if (step % swap_step == 0) and (step % (swap_step*n_swap_bet_avg_p1) != 0):\n",
    "        for client in client_selects:\n",
    "            client_weights[client] = fed_swap(client)\n",
    "    \n",
    "    if (step % (swap_step*n_swap_bet_avg_p1) == 0):\n",
    "        avg_weights = fed_avg()\n",
    "        global_model.set_weights(avg_weights) # update global model\n",
    "        select_clients_and_assign_weights(avg_weights)\n",
    "\n",
    "        # test global model and print out metrics after each communication round\n",
    "        global_acc, global_loss = test_neural_network(test_dataloader, global_model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0654,  0.0145, -0.0110,  ...,  0.0060, -0.0232, -0.0285],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0654,  0.0145, -0.0110,  ...,  0.0060, -0.0232, -0.0285],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0654,  0.0145, -0.0110,  ...,  0.0060, -0.0232, -0.0285],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(client_weights[0][0][0])\n",
    "print(client_weights[1][0][0])\n",
    "print(client_weights[2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
