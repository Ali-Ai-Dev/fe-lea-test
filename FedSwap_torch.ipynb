{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd \"/content/drive/MyDrive/ColabTemp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using '{device}' device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeed = 42\n",
    "torch.manual_seed(mySeed)\n",
    "np.random.seed(mySeed)\n",
    "random.seed(mySeed)\n",
    "# tf.random.set_seed(mySeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "num_clients = 5\n",
    "batch_size = 8\n",
    "\n",
    "remain = 0.01 # Remove some data for running faster in test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "torch.Size([3, 32, 32])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"../datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10).scatter_(dim=0, index=torch.tensor(y), value=1)),\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"../datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10).scatter_(dim=0, index=torch.tensor(y), value=1)),\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Remove some data for running faster in test\n",
    "print(len(train_data))\n",
    "train_data = torch.utils.data.Subset(train_data, range(0, int(len(train_data)*remain)))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random dataset split\n",
    "client_data_size = np.array([len(train_data)//num_clients]*num_clients)\n",
    "data_remain = len(train_data) % num_clients\n",
    "for i in range(data_remain):\n",
    "    client_data_size[-1-i] += 1\n",
    "\n",
    "client_datasets = torch.utils.data.random_split(train_data, client_data_size)\n",
    "\n",
    "### None random dataset split\n",
    "# client_datasets = list()\n",
    "# i = 0\n",
    "# for j in client_data_size:\n",
    "#     client_datasets.append(torch.utils.data.Subset(train_data, range(i, i+j)))\n",
    "#     i += j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader for each client\n",
    "client_dataloaders = np.zeros(num_clients, dtype=object)\n",
    "for i, dataset in enumerate(client_datasets):\n",
    "    client_dataloaders[i] = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "input_flat_size = torch.flatten(train_data[0][0]).shape[0]\n",
    "nClasses = train_data[0][1].shape[0]\n",
    "\n",
    "class NeuralNetworkMnistMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(input_flat_size, 256)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(256, 128)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc3', nn.Linear(128, 64)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('fc4', nn.Linear(64, nClasses)),\n",
    "        ]))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return list(self.parameters())\n",
    "    \n",
    "    def set_weights(self, parameters_list):\n",
    "        for i, param in enumerate(self.parameters()):\n",
    "            param.data = parameters_list[i].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworkMnistMLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetworkMnistMLP().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0130, -0.0093,  0.0144,  ..., -0.0096, -0.0016, -0.0117],\n",
       "        [ 0.0154,  0.0090,  0.0077,  ...,  0.0140,  0.0155, -0.0038],\n",
       "        [-0.0115,  0.0137, -0.0087,  ...,  0.0096,  0.0049, -0.0007],\n",
       "        ...,\n",
       "        [-0.0061, -0.0133,  0.0085,  ..., -0.0007, -0.0012, -0.0113],\n",
       "        [ 0.0166, -0.0064, -0.0151,  ...,  0.0163, -0.0075,  0.0139],\n",
       "        [ 0.0161,  0.0070,  0.0145,  ...,  0.0043, -0.0153, -0.0122]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_weights = model.get_weights()\n",
    "client_selects = torch.arange(0, num_clients)\n",
    "client_weights = [global_weights]*len(client_selects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
