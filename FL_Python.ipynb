{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hMM6D1tDTi4y"
      },
      "outputs": [],
      "source": [
        "# url = \"https://usaupload.com/72Eb/mnist.zip?download_token=122af6eb9e746e2774d3422cba7775dd9ca2a43aaa3156f4c0b5043723a24823\"\n",
        "# name = url.split(\"/\")[-1]\n",
        "# fileName = name.split(\"?\")[0]\n",
        "\n",
        "# !wget $url\n",
        "# !mv $name $fileName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sGtX5o7VTi41"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !unzip mnist.zip;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RzTrKyXWTi41"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "mySeed = 42\n",
        "np.random.seed(mySeed)\n",
        "random.seed(mySeed)\n",
        "tf.random.set_seed(mySeed)\n",
        "# torch.manual_seed(mySeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XpvfFXbOTi42"
      },
      "outputs": [],
      "source": [
        "def load_mnist_bypath(paths, verbose=-1):\n",
        "    \"\"\" Expect to read images where each class is in a separate directory,\n",
        "        For example: images of type 0 are in folder 0\n",
        "    \"\"\"\n",
        "\n",
        "    data = list()\n",
        "    labels = list()\n",
        "    # loop over the input images\n",
        "    for (i, imgpath) in enumerate(paths):\n",
        "        # load the image and extract the class labels\n",
        "        im_gray = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "        image = np.array(im_gray).flatten()\n",
        "        label = imgpath.split(os.path.sep)[-2]\n",
        "        # here the img is scaled to [0, 1] to less the impact of each pixel's brightness\n",
        "        data.append(image/255)\n",
        "        labels.append(label)\n",
        "        # show an update every `verbose` images\n",
        "        if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
        "            print(f\"[INFO] processed {i+1}/{len(paths)}\")\n",
        "            break\n",
        "\n",
        "    # return a tuple of the data and labels\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8GgAuQUTi42",
        "outputId": "831655d7-1881-4f0b-af32-8b086b90c6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] processed 10000/42000\n"
          ]
        }
      ],
      "source": [
        "# Declare mnist dataset path\n",
        "img_path = \"mnist/trainingSet/trainingSet\"\n",
        "# img_path = \"/content/mnist/trainingSet/trainingSet\"\n",
        "\n",
        "# Generate a list of trucks using the list_images function from the paths library\n",
        "image_paths = list(paths.list_images(img_path))\n",
        "\n",
        "# load images into arrays\n",
        "image_list, label_list = load_mnist_bypath(image_paths, verbose=10000)\n",
        "\n",
        "# Perform the one-hot encoded so we can use the sparse-categorical-entropy loss function\n",
        "lb = LabelBinarizer()\n",
        "label_list = lb.fit_transform(label_list)\n",
        "\n",
        "#split data into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4LqxZDHMTi43"
      },
      "outputs": [],
      "source": [
        "def create_clients(image_list, label_list, num_clients=10, initial=\"clients\"):\n",
        "    \"\"\" return: A dictionary with the customer id as the dictionary key and the value\n",
        "                will be the data fragment - tuple of images and labels.\n",
        "        args:\n",
        "            image_list: a numpy array object with the images\n",
        "            label_list: list of binarized labels (one-hot encoded)\n",
        "            num_client: number of customers (clients)\n",
        "            initials: the prefix of the clients, e.g., clients_1\n",
        "     \"\"\"\n",
        "\n",
        "    # create list of customer names\n",
        "    client_names = [f\"{initial}_{i+1}\" for i in range(num_clients)]\n",
        "\n",
        "    # shuffle the data\n",
        "    data = list(zip(image_list, label_list))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    # shard the data and split it for each customer\n",
        "    size = len(data) // num_clients\n",
        "    shards = [data[i: i+size] for i in range(0, size * num_clients, size)]\n",
        "\n",
        "    # Check if the fragment number is equal to the number of clients\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i]: shards[i] for i in range(len(client_names))}\n",
        "\n",
        "\n",
        "num_clients = 2\n",
        "# Create the customers\n",
        "clients = create_clients(X_train, y_train, num_clients=num_clients, initial=\"client\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_xXnY6tFTi43"
      },
      "outputs": [],
      "source": [
        "def batch_data(data_shard, b=32):\n",
        "    \"\"\" Receives a piece of data from a client and creates a tensorflow data object in it\n",
        "        args:\n",
        "            data_shard: data and labels that make up a customer's data shard\n",
        "            b: batch size\n",
        "        return:\n",
        "            data tensorflow object\n",
        "    \"\"\"\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(b)\n",
        "\n",
        "\n",
        "# Process and collate the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "\n",
        "# process and group test set\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[([1, 2], 'a'), ([3, 4], 'b'), ([5, 6], 'c'), ([7, 8], 'd')]\n",
            "([1, 2], [3, 4], [5, 6], [7, 8])\n",
            "('a', 'b', 'c', 'd')\n",
            "([[1, 2], [3, 4], [5, 6], [7, 8]], ['a', 'b', 'c', 'd']) \n",
            "\n",
            "[(array([5, 6]), b'c'), (array([3, 4]), b'b'), (array([7, 8]), b'd'), (array([1, 2]), b'a')]\n",
            "[(array([[1, 2],\n",
            "       [5, 6],\n",
            "       [3, 4],\n",
            "       [7, 8]]), array([b'a', b'c', b'b', b'd'], dtype=object))]\n",
            "---------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=4>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = list(zip([[1, 2], [3, 4], [5, 6], [7, 8]], [\"a\", \"b\", \"c\", \"d\"]))\n",
        "print(test)\n",
        "data, label = zip(*test)\n",
        "print(data)\n",
        "print(label)\n",
        "\n",
        "print((list(data), list(label)), \"\\n\")\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "test1 = dataset.shuffle(len(label))\n",
        "print(list(test1.as_numpy_iterator()))\n",
        "test2 = dataset.shuffle(len(label)).batch(4)\n",
        "print(list(test2.as_numpy_iterator()))\n",
        "\n",
        "print(\"---------\")\n",
        "list(test2)[0][0].shape[0]\n",
        "\n",
        "tf.data.experimental.cardinality(test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xe1ZFi2gTi44"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(100, input_shape=(shape,)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(100))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        return model\n",
        "\n",
        "lr = 0.01\n",
        "comms_round = 1\n",
        "loss = \"categorical_crossentropy\"\n",
        "metrics = [\"accuracy\"]\n",
        "# optimizer = SGD(lr=lr, decay=lr/comms_round, momentum=0.9)\n",
        "# optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, decay=lr/comms_round, momentum=0.9)\n",
        "\n",
        "# optimizer = optimizers.Adam(learning_rate=lr, decay=lr/comms_round)\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr, decay=lr/comms_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LiDTqgXgTi44"
      },
      "outputs": [],
      "source": [
        "def weight_scalling_factor(clients_trn_data, client_name, participants):\n",
        "    \"\"\" Calculates the size ratio of a client's local training data\n",
        "        with all general training data maintained by all customers\n",
        "    \"\"\"\n",
        "    # client_names = list(clients_trn_data.keys())\n",
        "    # calculate batch size\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    # first calculate total training data across clients\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()\n",
        "                        for client_name in participants]) * bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() * bs\n",
        "\n",
        "    return local_count / global_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7wFLVmqtTi44"
      },
      "outputs": [],
      "source": [
        "def scale_model_weights(weight, scalar):\n",
        "    \"\"\" Scale the model weights \"\"\"\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "\n",
        "    return weight_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uTH6M7XCTi45"
      },
      "outputs": [],
      "source": [
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    \"\"\" Return the sum of the listed scaled weights. O is equivalent to the average weight of the weights \"\"\"\n",
        "    avg_grad = list()\n",
        "    # get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JJNKf44FTi45"
      },
      "outputs": [],
      "source": [
        "def test_model(X_test, Y_test, model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    # logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    # print(f\"Agregation Round: {comm_round} | global_acc: {acc:.3%} | global_loss: {loss}\"\")\n",
        "    print(f\"round: {comm_round} | acc: {acc:.3%} | loss: {loss}\")\n",
        "\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k8wrKPisTi45"
      },
      "outputs": [],
      "source": [
        "def check_local_loss(client, model):\n",
        "    # Check local loss\n",
        "    cce_l = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    client_x = np.array([i[0] for i in clients[client]])\n",
        "    client_y = np.array([i[1] for i in clients[client]])\n",
        "    logits_l = model.predict(client_x)\n",
        "    loss_l = cce_l(client_y, logits_l)\n",
        "    acc_l = accuracy_score(tf.argmax(logits_l, axis=1), tf.argmax(client_y, axis=1))\n",
        "    print(f\"Local accuracy: {acc_l}. Local loss: {loss_l}\")\n",
        "\n",
        "    return acc_l, loss_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)\n",
        "np.array(X_train).shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBZ4LjTTi45",
        "outputId": "d0e7901a-d638-4f40-fe7f-a9369b4e07f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "[array([[-0.10273433, -0.04704752,  0.00808045, ...,  0.00588168,\n",
            "        -0.00892175,  0.04568826],\n",
            "       [-0.08046277, -0.08837207,  0.07953828, ..., -0.01924175,\n",
            "        -0.0003405 ,  0.05012558],\n",
            "       [-0.10633839,  0.07703272,  0.14993031, ..., -0.06314261,\n",
            "         0.07507354, -0.00307084],\n",
            "       ...,\n",
            "       [ 0.03414189,  0.04948349, -0.01683494, ..., -0.01540671,\n",
            "        -0.00967073, -0.07834828],\n",
            "       [ 0.01090276,  0.02770779, -0.04498865, ...,  0.01563124,\n",
            "        -0.06267883,  0.01385543],\n",
            "       [-0.00375625,  0.04419962, -0.04669923, ..., -0.076101  ,\n",
            "         0.07397996,  0.02152165]], dtype=float32), array([ 0.03723201, -0.04715949, -0.02667499, -0.04260452,  0.03148138,\n",
            "        0.04119247, -0.04683567, -0.01977017, -0.07218076, -0.01400004,\n",
            "       -0.10265955,  0.01042398, -0.06595653, -0.01400225, -0.04816522,\n",
            "       -0.05215771, -0.01774358, -0.03047093, -0.01886008,  0.00966555,\n",
            "       -0.0549637 ,  0.03881105, -0.07077589, -0.00620759,  0.00185924,\n",
            "        0.01631066,  0.04037812,  0.00283107, -0.05578178, -0.04754793,\n",
            "       -0.01379986,  0.01568229, -0.04822458, -0.07094528, -0.00395515,\n",
            "       -0.05998914,  0.02758306,  0.01290183, -0.01599791,  0.03929393,\n",
            "       -0.06392641, -0.05643584,  0.01140265, -0.01093269, -0.01912648,\n",
            "       -0.08257724, -0.04822549, -0.07100864, -0.04783775,  0.03144199,\n",
            "       -0.08266336, -0.08337688, -0.02622187,  0.02436901, -0.0636531 ,\n",
            "       -0.03247901, -0.04822822,  0.03792407, -0.04822777,  0.00202537,\n",
            "       -0.01835937, -0.00446334,  0.02968733, -0.05489879, -0.04512729,\n",
            "       -0.05494712,  0.03393057, -0.03496018, -0.08228634,  0.02757204,\n",
            "        0.0114338 , -0.002656  ,  0.05423365, -0.04124693, -0.0694514 ,\n",
            "       -0.04659661, -0.04953084, -0.01495561, -0.03992844, -0.06088677,\n",
            "       -0.07314098, -0.03071981,  0.00474601, -0.06472234, -0.04139282,\n",
            "       -0.04820639, -0.02230977, -0.07018936,  0.01124178, -0.0240875 ,\n",
            "        0.00100899,  0.0328096 ,  0.021269  ,  0.02965945, -0.04821718,\n",
            "       -0.03909143, -0.06428382, -0.03429886, -0.0623582 ,  0.05138769],\n",
            "      dtype=float32), array([[-0.04105549, -0.04641354, -0.09233673, ..., -0.12860964,\n",
            "         0.07693252, -0.21654536],\n",
            "       [ 0.09752505,  0.07693777, -0.06631989, ..., -0.09056797,\n",
            "        -0.08531123, -0.12884471],\n",
            "       [ 0.04642583, -0.01325531,  0.09315161, ..., -0.11627191,\n",
            "         0.03628012, -0.03874115],\n",
            "       ...,\n",
            "       [ 0.15330702, -0.0484661 ,  0.03316047, ...,  0.11638056,\n",
            "        -0.02369896, -0.00472911],\n",
            "       [-0.16395913,  0.0417553 ,  0.12576196, ...,  0.06473473,\n",
            "        -0.01798511, -0.0091185 ],\n",
            "       [-0.06392878, -0.07388621, -0.03363683, ..., -0.20511997,\n",
            "        -0.14770699, -0.11775352]], dtype=float32), array([-0.02745952,  0.00797684, -0.03612022, -0.04798899, -0.01441651,\n",
            "        0.04808928, -0.02603552, -0.04175762,  0.00690148, -0.04720785,\n",
            "       -0.02224632,  0.00989642, -0.0553166 , -0.06281897, -0.0891706 ,\n",
            "       -0.06883631, -0.03429288, -0.00498497, -0.05973136,  0.10087442,\n",
            "        0.05270108, -0.02949354,  0.06065743,  0.03915047, -0.04808409,\n",
            "        0.01079035, -0.03674339,  0.00646306, -0.05156651, -0.02891088,\n",
            "       -0.05886182, -0.05093786,  0.01492774,  0.05524283,  0.03424671,\n",
            "       -0.02035978, -0.05043198, -0.00806302, -0.05361318,  0.07121056,\n",
            "       -0.02627694, -0.0573156 , -0.07297606,  0.05453487, -0.05063091,\n",
            "        0.07437477, -0.04822613,  0.00191859,  0.05394356,  0.05035331,\n",
            "       -0.06273795,  0.00498284,  0.05114723,  0.01370541,  0.00918656,\n",
            "       -0.02446218,  0.05701901,  0.10878053, -0.04847343,  0.02025103,\n",
            "       -0.04823299, -0.07431944, -0.02675448, -0.00648841, -0.10038029,\n",
            "       -0.07154668,  0.0387118 , -0.02951088, -0.08648205,  0.02575022,\n",
            "       -0.05894666,  0.06364096,  0.03728325, -0.04720384, -0.00238884,\n",
            "       -0.03940534,  0.02098707, -0.07301909, -0.0591263 , -0.07496768,\n",
            "       -0.08674981, -0.06232458, -0.12272274,  0.00769642, -0.0156975 ,\n",
            "        0.03989137, -0.0201713 , -0.07809544,  0.05559082,  0.06208977,\n",
            "       -0.0407099 , -0.07704097, -0.01994666,  0.06040089,  0.06224047,\n",
            "        0.00196615, -0.05606188, -0.06102243,  0.01091739, -0.08660494],\n",
            "      dtype=float32), array([[-0.21064965, -0.14320871,  0.18420206],\n",
            "       [-0.18569966, -0.36357078, -0.09624676],\n",
            "       [ 0.10411572, -0.22577573, -0.17123064],\n",
            "       [-0.02398699, -0.2535657 , -0.16390151],\n",
            "       [-0.09745523, -0.04226752, -0.12589613],\n",
            "       [-0.05456873,  0.27235132, -0.07206239],\n",
            "       [-0.12231459, -0.14015336, -0.00451352],\n",
            "       [ 0.07889371, -0.03196087, -0.11245147],\n",
            "       [ 0.22769178,  0.24492389,  0.0221271 ],\n",
            "       [-0.01230461,  0.2368166 , -0.19285291],\n",
            "       [-0.03412601, -0.16661577,  0.05582982],\n",
            "       [-0.05165985,  0.07791422, -0.14953327],\n",
            "       [-0.01045193, -0.00097119,  0.00096998],\n",
            "       [-0.10151837, -0.08208939,  0.10129901],\n",
            "       [ 0.04122004, -0.02240292,  0.03144672],\n",
            "       [-0.1607709 ,  0.03966116, -0.03266542],\n",
            "       [ 0.08367414, -0.10070585,  0.02381863],\n",
            "       [ 0.12135731, -0.22271033,  0.20051318],\n",
            "       [ 0.18063894,  0.06731179, -0.09270962],\n",
            "       [-0.03794077,  0.12411559,  0.11292687],\n",
            "       [-0.18251802,  0.18489617, -0.00798925],\n",
            "       [ 0.17327906, -0.13728617,  0.18510456],\n",
            "       [-0.22687654,  0.07936678,  0.0228559 ],\n",
            "       [-0.07735525,  0.04994698, -0.21175449],\n",
            "       [ 0.01714201, -0.03932487,  0.14420702],\n",
            "       [ 0.02135046,  0.09710712, -0.06173953],\n",
            "       [ 0.03996809, -0.22536077, -0.0389965 ],\n",
            "       [-0.18541582,  0.04193794, -0.08296522],\n",
            "       [ 0.2005437 , -0.08952287,  0.09966298],\n",
            "       [-0.30303288, -0.08352721, -0.11988239],\n",
            "       [-0.16078678, -0.15259393, -0.13392113],\n",
            "       [ 0.00609213, -0.17059186, -0.14918542],\n",
            "       [-0.2235432 , -0.00900123,  0.19623624],\n",
            "       [-0.24434976,  0.23500597, -0.24106497],\n",
            "       [-0.15061423, -0.02960696, -0.16474912],\n",
            "       [ 0.12108704,  0.21700655, -0.07194147],\n",
            "       [-0.11782543, -0.11731791,  0.06232539],\n",
            "       [-0.25680232, -0.14475538, -0.20426893],\n",
            "       [ 0.10614891, -0.10086977, -0.22048312],\n",
            "       [-0.14671117,  0.11824607,  0.0743494 ],\n",
            "       [-0.04825314, -0.2556225 ,  0.04100222],\n",
            "       [ 0.07649489, -0.23779655,  0.17230171],\n",
            "       [-0.10409466, -0.12772761, -0.22433582],\n",
            "       [-0.00963832,  0.14655054,  0.19743207],\n",
            "       [ 0.11963055, -0.2129602 , -0.13639243],\n",
            "       [-0.2705756 ,  0.06323376, -0.08350809],\n",
            "       [-0.16243033, -0.14230625, -0.13804999],\n",
            "       [-0.16783169,  0.14460067, -0.00413032],\n",
            "       [-0.24164923,  0.00454473, -0.15251803],\n",
            "       [-0.1444975 ,  0.21163131, -0.12725373],\n",
            "       [ 0.10430655,  0.01616045, -0.19159697],\n",
            "       [ 0.14222804,  0.2088005 , -0.16245371],\n",
            "       [-0.02689493,  0.25503042,  0.1396978 ],\n",
            "       [-0.2685034 , -0.11095501, -0.12784685],\n",
            "       [ 0.06397702,  0.07146236,  0.07866123],\n",
            "       [-0.05911613,  0.0803781 ,  0.21190804],\n",
            "       [-0.24559799,  0.138983  , -0.18447363],\n",
            "       [-0.20466888,  0.06908079, -0.00516359],\n",
            "       [-0.08620344, -0.24476488,  0.1555308 ],\n",
            "       [-0.22991087, -0.13495658, -0.1499666 ],\n",
            "       [-0.05058343,  0.18396825,  0.1468511 ],\n",
            "       [-0.09979001, -0.23450263,  0.1452647 ],\n",
            "       [ 0.09727639,  0.10994556, -0.31288755],\n",
            "       [ 0.00138205, -0.26271287, -0.20591578],\n",
            "       [ 0.11886092,  0.03490222, -0.02087544],\n",
            "       [-0.01178201,  0.05247529,  0.09652469],\n",
            "       [ 0.05037475, -0.10567615,  0.15741484],\n",
            "       [-0.02860396,  0.06757367, -0.10311001],\n",
            "       [ 0.11026613, -0.01069087,  0.10702576],\n",
            "       [-0.17254896,  0.1791307 ,  0.04165385],\n",
            "       [ 0.01745063,  0.00104566, -0.20437612],\n",
            "       [ 0.02352321,  0.25173622, -0.1186923 ],\n",
            "       [-0.06561157,  0.12825596,  0.01344583],\n",
            "       [-0.2390108 , -0.13583441, -0.1396431 ],\n",
            "       [-0.01882305, -0.19749968,  0.00272308],\n",
            "       [ 0.09535997, -0.05125505, -0.23216183],\n",
            "       [-0.0559807 , -0.15723108,  0.07335955],\n",
            "       [ 0.02993613, -0.06500427, -0.05865273],\n",
            "       [-0.1208469 , -0.18835224, -0.04519325],\n",
            "       [-0.0863206 , -0.09102611, -0.0851009 ],\n",
            "       [ 0.0048684 , -0.0976694 , -0.03465494],\n",
            "       [-0.07414868,  0.01842813, -0.01048266],\n",
            "       [ 0.10262812, -0.00387046, -0.00380023],\n",
            "       [-0.18914528, -0.02741686, -0.02537105],\n",
            "       [ 0.01316038, -0.14058045,  0.19551401],\n",
            "       [-0.00804405,  0.15988824, -0.16921042],\n",
            "       [ 0.14341187,  0.24227355, -0.00979284],\n",
            "       [ 0.09157623, -0.2184252 , -0.02042664],\n",
            "       [ 0.03488243, -0.10195383,  0.19604152],\n",
            "       [-0.15278162, -0.05243636, -0.18299167],\n",
            "       [ 0.20090008, -0.25180975, -0.21702434],\n",
            "       [ 0.07189422, -0.07433221, -0.00186784],\n",
            "       [ 0.14401712,  0.16404659, -0.05916506],\n",
            "       [-0.25130367,  0.14622232, -0.0142874 ],\n",
            "       [-0.2631371 ,  0.1103764 ,  0.24253309],\n",
            "       [ 0.18866949,  0.13107151, -0.0753332 ],\n",
            "       [-0.08966541, -0.10280708, -0.08875725],\n",
            "       [-0.30187628, -0.1000718 ,  0.16256766],\n",
            "       [ 0.0028405 , -0.04759025, -0.22570282],\n",
            "       [ 0.05833314, -0.0046204 ,  0.11794461]], dtype=float32), array([-0.06675667,  0.06099342,  0.00333587], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "client_select_rate = 0.6\n",
        "client_select_rate = 1\n",
        "client_epochs = 1\n",
        "### Start global template ###\n",
        "\n",
        "smlp_global = MLP()\n",
        "global_model = smlp_global.build(784, np.array(y_train).shape[-1])\n",
        "\n",
        "# Global training loop collection\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    # initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    # randomize client data - using keys\n",
        "    client_names = list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "    client_select = client_names[0: int(num_clients*client_select_rate)]\n",
        "    # print(client_select)\n",
        "\n",
        "    # loop through each client and create a new local model\n",
        "    for client in client_select:\n",
        "        smlp_local = MLP()\n",
        "        local_model = smlp_local.build(784, np.array(y_train).shape[-1])\n",
        "        local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "        # set the weight of the local model to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        # fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=client_epochs, verbose=0)\n",
        "\n",
        "        # scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client, client_select)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        print(\"test\")\n",
        "        print(local_model.get_weights())\n",
        "        \n",
        "        break\n",
        "\n",
        "    #     # Check local accuracy\n",
        "    #     # acc_l, loss_l = check_local_loss(client, local_model)\n",
        "\n",
        "    #     # clear session to free memory after each communication round\n",
        "    #     K.clear_session()\n",
        "\n",
        "    # # to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    # average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    # # update global model\n",
        "    # global_model.set_weights(average_weights)\n",
        "\n",
        "    # # test global model and print out metrics after each communications round\n",
        "    # for (X_test, Y_test) in test_batched:\n",
        "    #     global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRTxww2PTi46"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-jfRsbtTi46"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
